{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from model_tit import *\n",
    "from timeit import default_timer as timer\n",
    "import util\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.sampler import SequentialSampler\n",
    "\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "\n",
    "\n",
    "# start here ! ###################################################################################\n",
    "def do_predict(net, tokenizer, valid_loader):\n",
    "\n",
    "    text = []\n",
    "\n",
    "    start_timer = timer()\n",
    "    valid_num = 0\n",
    "    for t, batch in enumerate(valid_loader):\n",
    "        batch_size = len(batch['image'])\n",
    "        image = batch['image'].cuda()\n",
    "\n",
    "\n",
    "        net.eval()\n",
    "        with torch.no_grad():\n",
    "            k = net.forward_argmax_decode(image)\n",
    "            k = k.data.cpu().numpy()\n",
    "            k = tokenizer.predict_to_inchi(k)\n",
    "            text.extend(k)\n",
    "\n",
    "        valid_num += batch_size\n",
    "        print('\\r %8d / %d  %s' % (valid_num, len(valid_loader.dataset), util.time_to_str(timer() - start_timer, 'sec')),\n",
    "              end='', flush=True)\n",
    "\n",
    "    assert(valid_num == len(valid_loader.dataset))\n",
    "    print('')\n",
    "    return text\n",
    "\n",
    "\n",
    "#fold = 0\n",
    "out_dir = '/content/drive/MyDrive/molecule/server_code/model/tit0'.format(fold)\n",
    "initial_checkpoint = '/Users/zhenyuanzhang/Desktop/udemy/AWS_Lambda_and_Serverless/IMG2InChi/100000_model.pth'#None #\n",
    "\n",
    "is_norm_ichi = False #True\n",
    "if 1:\n",
    "\n",
    "    ## setup  ----------------------------------------\n",
    "    mode = 'local'\n",
    "\n",
    "    submit_dir = '/Users/zhenyuanzhang/Desktop/udemy/AWS_Lambda_and_Serverless/IMG2InChi'\n",
    "    os.makedirs(submit_dir, exist_ok=True)\n",
    "\n",
    "    ## dataset ------------------------------------\n",
    "    tokenizer = util.load_tokenizer()\n",
    "    df_valid = pd.read_pickle('/content/drive/MyDrive/molecule/server_code/data/df_test.pkl')\n",
    "\n",
    "    valid_dataset = util.BmsDataset(df_valid, tokenizer, mode = 'test', augment=util.rot_augment)\n",
    "    valid_loader  = DataLoader(\n",
    "        valid_dataset,\n",
    "        sampler = SequentialSampler(valid_dataset),\n",
    "        #sampler = util.FixNumSampler(valid_dataset, 100),\n",
    "        batch_size  = 64, #32,\n",
    "        drop_last   = False,\n",
    "        num_workers = 8,\n",
    "        pin_memory  = True,\n",
    "        collate_fn  = lambda batch: util.collate_fn(batch,False)\n",
    "    )\n",
    "\n",
    "    start_timer = timer()\n",
    "\n",
    "    tokenizer = util.load_tokenizer()\n",
    "    net = Net().cuda()\n",
    "    net.load_state_dict(torch.load(initial_checkpoint)['state_dict'], strict=True)\n",
    "\n",
    "    #---\n",
    "    predict = do_predict(net, tokenizer, valid_loader)\n",
    "\n",
    "    #print('time taken : %s\\n\\n' % util.time_to_str(timer() - start_timer, 'min'))\n",
    "    #----\n",
    "\n",
    "\n",
    "    # if is_norm_ichi:\n",
    "    #     predict = [normalize_inchi(t) for t in predict]  #\n",
    "\n",
    "    # df_submit = pd.DataFrame()\n",
    "    # df_submit.loc[:,'image_id'] = df_valid.image_id.values\n",
    "    # df_submit.loc[:,'InChI'] = predict #\n",
    "    # df_submit.to_csv(submit_dir + '/186000submit.csv', index=False)\n",
    "\n",
    "    # print('submit_dir : %s\\n' % (submit_dir))\n",
    "    # print('initial_checkpoint : %s\\n' % (initial_checkpoint))\n",
    "    # print('df_submit : %s\\n' % str(df_submit.shape))\n",
    "    # print('%s\\n' % str(df_submit))\n",
    "    # print('\\n')\n",
    "\n",
    "    print(predict)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    pass\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
